# -*- coding: utf-8 -*-
"""tech_challenge.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X4NwAOw4YDBejrp-IV_ipfj-XWSaPuWl

**Tech Challenge - Fase 01**

Grupo de Trabalho:
- Izabela de Souza Oliveira RM364554
- Rafael Almeida RM362308
- Thais Tozatto RM363288

##Importing libraries
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder, OrdinalEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression, Lasso
from xgboost import XGBRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor

"""##Data exploration"""

df = pd.read_csv('https://raw.githubusercontent.com/isoliveira20/POS-IA/refs/heads/main/health_insurance_dataset_v3.csv')
print(df.head()) #imprime as 5 primeiras linhas
print(df.shape)  # Verifica quantas linhas e colunas tem
print(df.count())

"""##Data and columns info"""

print(df.info())

"""##Statistics for Numerical Columns"""

print(df.describe())

"""Data cleaning and format"""

numerical_vars = [
    'age', 'income', 'num_dependents_kids', 'num_dependents_adult',
    'num_dependents_older', 'use_last_year', 'chronic_condition', 'occupation_risk'
]

bool_vars = [
    'smoker'
]

categorical_nominal_vars = [
    'sex', 'region', 'marital_status'
]

categorical_ordinal_vars = [
    'exercise_frequency', 'bmi',
    'diet_quality', 'education', 'alcohol_consumption', 'coverage_level',
    'genetic_risk'
]

target = 'charges'

random_state = 42

order_exercise_frequency = ['sedentary', 'light', 'moderate', 'active']
order_bmi = ['underweight', 'normal', 'overweight', 'obese']
order_diet_quality = ['poor', 'average', 'good']
order_education = ['primary', 'high_school', 'college', 'postgraduate']
order_alcohol_consumption = ['none', 'low', 'moderate', 'high']
order_coverage_level = ['basic', 'standard', 'premium']
order_genetic_risk = ['low', 'medium', 'high']

"""Agora iremos criar os transformers para cada tipo de dado"""

# Variáveis
numerical_vars = ['age', 'income', 'num_dependents_kids', 'num_dependents_adult',
                  'num_dependents_older', 'use_last_year', 'chronic_condition', 'occupation_risk']
bool_vars = ['smoker']
categorical_nominal_vars = ['sex', 'region', 'marital_status']
categorical_ordinal_vars = ['exercise_frequency', 'bmi', 'diet_quality', 'education',
                            'alcohol_consumption', 'coverage_level', 'genetic_risk']

# Ordens das variáveis ordinais
order_exercise_frequency = ['sedentary', 'light', 'moderate', 'active']
order_bmi = ['underweight', 'normal', 'overweight', 'obese']
order_diet_quality = ['poor', 'average', 'good']
order_education = ['primary', 'high_school', 'college', 'postgraduate']
order_alcohol_consumption = ['none', 'low', 'moderate', 'high']
order_coverage_level = ['basic', 'standard', 'premium']
order_genetic_risk = ['low', 'medium', 'high']

# Transformers
nominal_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

ordinal_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('ordinal', OrdinalEncoder(categories=[
        order_exercise_frequency, order_bmi, order_diet_quality, order_education,
        order_alcohol_consumption, order_coverage_level, order_genetic_risk
    ]))
])

numerical_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

bool_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent'))
])

# ColumnTransformer
preprocessor = ColumnTransformer(transformers=[
    ('nominal', nominal_transformer, categorical_nominal_vars),
    ('ordinal', ordinal_transformer, categorical_ordinal_vars),
    ('bool', bool_transformer, bool_vars),
    ('num', numerical_transformer, numerical_vars)
])

# Aplicar transformação
X = df.drop(columns=['charges'])
preprocessor.fit(X)
X_transformed = preprocessor.transform(X)

# Reconstruir DataFrame
nominal_features = preprocessor.named_transformers_['nominal'].named_steps['onehot'].get_feature_names_out(categorical_nominal_vars)
ordinal_features = categorical_ordinal_vars
bool_features = bool_vars
num_features = numerical_vars
all_feature_names = list(nominal_features) + ordinal_features + bool_features + num_features
df_transformed = pd.DataFrame(X_transformed, columns=all_feature_names)
df_transformed['charges'] = df['charges'].values

"""Mantém o df orignal para uso em exibições. Cria um transformado para uso em treinamento

##Missing Values and Data Cleaning
"""

# prints the sum of missing values per column
print(df.isnull().sum())

#handling of missing values
#df['bmi'] = df['bmi'].fillna(df['bmi'].mode()[0])

# prints the sum of missing values per column
print(df_transformed.isnull().sum())

"""##Duplicate values"""

print(df.duplicated().sum())
print(df_transformed.duplicated().sum())

"""✅ Conforme o resultado, não existem valores duplicados na base de dados.

Showing both Data Frames
"""

print(df.head())

print(df_transformed.head())

"""##Distribution of Variables"""

sns.pairplot(df, vars=('age', 'sex', 'bmi', 'smoker', 'marital_status', 'exercise_frequency', 'income', 'charges', 'diet_quality', 'region', 'coverage_level','genetic_risk', 'use_last_year', 'num_dependents_kids','num_dependents_adult','num_dependents_older'))
plt.show()

"""##Converting Categorical Variables to Numerical Using LabelEncoder"""

label_encoder = LabelEncoder()
for col in ['sex','region','exercise_frequency','bmi','marital_status','diet_quality', 'education', 'alcohol_consumption','coverage_level','genetic_risk']:
    df[col] = label_encoder.fit_transform(df[col])

#Checking the transformation
print(df.head())

"""##Histogramas"""

# Histograms
df[['age', 'sex', 'bmi', 'smoker', 'income', 'charges', 'genetic_risk','use_last_year' ]].hist(bins=30, figsize=(10, 6))
plt.tight_layout()
plt.show()

"""✅ **Resultados das análises:**
1. A população analisada é predominantemente do sexo feminino.
2. A idade da população varia de 15 a 90 anos, e a idade média é 35 anos.
3. Em relação ao estado civil, as maiores concentrações estão em casados, solteiros, viúvos e divorciados, respectivamente.
4. A maioria das pessoas não são fumantes.
5. A renda anual tem crescimento conforme a idade.
6. Há forte relação de crescimento do valor gasto com seguro saúde à medida que a idade da população aumenta.
7. Há forte relação de crescimento da quantidade de usos no ultimo ano à medida que a idade da população aumenta.
8. A quantidade de usos também aumenta nas pessoas com maiores salários
9. A maior parte de fumantes são adultos (25~45 anos)

##Correlation matrix
"""

plt.figure(figsize=(12, 8))
correlation_matrix = df.corr(numeric_only=True, method="spearman")
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Matriz de Correlação')
plt.show()

"""Correlation Matrix - Transformed"""

plt.figure(figsize=(12, 8))
correlation_matrix = df_transformed.corr(numeric_only=True, method="spearman")
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Matriz de Correlação - Transformed')
plt.show()

"""##Split the data into feature variables (X) and target variable (y)"""

x = df_transformed.drop('charges', axis=1)
#x = df[['age','sex','region','bmi','smoker','income','num_dependents_kids','num_dependents_adult','num_dependents_older','coverage_level','use_last_year']]
y = df_transformed['charges']

"""##Split the dataset into training and testing sets (80% training, 20% testing)"""

X_train, X_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=42)

"""##Machine learning model application | Linear regression:"""

#Initializing the Linear Regression Model
model = LinearRegression()

# Training the model with the test data
model.fit(X_train, y_train)

# Making predictions with the test data
y_pred = model.predict(X_test)

# Evaluating the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)
print("MAE:", mae)
print("MSE:", mse)
print("RMSE:", rmse)
print("R2:", r2)

# Visualizing the results
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred)
plt.xlabel('Valores Reais')
plt.ylabel('Valores Preditos')
plt.title('Valores Reais vs Valores Preditos')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)
plt.show()

"""##Machine learning model application | XGBoost Regressor

"""

# Creating the XGBoost Regressor Model
xgb_model = XGBRegressor(n_estimators=100, random_state=42)

# Training the model with the test data
xgb_model.fit(X_train, y_train)

# Making predictions with the test data
y_pred_xgb = xgb_model.predict(X_test)

# Evaluating the model
mae_xgb = mean_absolute_error(y_test, y_pred_xgb)
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
rmse_xgb = np.sqrt(mse_xgb)
r2_xgb = r2_score(y_test, y_pred_xgb)
print("MAE XGBoost:", mae_xgb)
print("MSE XGBoost:", mse_xgb)
print("RMSE XGBoost:", rmse_xgb)
print("R2 XGBoost:", r2_xgb)

# Visualizing the results
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_xgb)
plt.xlabel('Valores Reais')
plt.ylabel('Valores Preditos')
plt.title('Valores Reais vs Valores Preditos')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)
plt.show()

"""##Machine learning model application | Lasso Regression"""

# Creating the Lasso Regression Model
lasso_model = Lasso(alpha=0.1)

# Training the model with the test data
lasso_model.fit(X_train, y_train)

# Making predictions with the test data
y_pred_lasso = lasso_model.predict(X_test)

# Evaluating the model
mae_lasso = mean_absolute_error(y_test, y_pred_lasso)
mse_lasso = mean_squared_error(y_test, y_pred_lasso)
rmse_lasso = np.sqrt(mse_lasso)
r2_lasso = r2_score(y_test, y_pred_lasso)
print("MAE Lasso:", mae_lasso)
print("MSE Lasso:", mse_lasso)
print("RMSE Lasso:", rmse_lasso)
print("R2 Lasso:", r2_lasso)

# Visualizing the results
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_lasso)
plt.xlabel('Valores Reais')
plt.ylabel('Valores Preditos')
plt.title('Valores Reais vs Valores Preditos')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)
plt.show()

"""##Machine learning model application | Random Forest Regressor"""

# Creating the Random Forest Regressor Model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

# Training the model with the test data
rf_model.fit(X_train, y_train)

# Making predictions with the test data
y_pred_rf = rf_model.predict(X_test)

# Evaluating the model
mae_rf = mean_absolute_error(y_test, y_pred_rf)
mse_rf = mean_squared_error(y_test, y_pred_rf)
rmse_rf = np.sqrt(mse_rf)
r2_rf = r2_score(y_test, y_pred_rf)
print("MAE Random Forest:", mae_rf)
print("MSE Random Forest:", mse_rf)
print("RMSE Random Forest:", rmse_rf)
print("R2 Random Forest:", r2_rf)

# Visualizing the results
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_rf)
plt.xlabel('Valores Reais')
plt.ylabel('Valores Preditos')
plt.title('Valores Reais vs Valores Preditos Random Forest')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)
plt.show()

"""##Final pipeline | Model accuracy | Best Model

Verificação manual do melhor modelo encontrado dentre os modelos aplicados.
"""

results = {r2, r2_xgb, r2_lasso, r2_rf}

# Store the results in a dictionary with model names as keys and R2 scores as values
results = {
    'Linear Regression': r2,
    'XGBoost Regressor': r2_xgb,
    'Lasso Regression': r2_lasso,
    'Random Forest Regressor': r2_rf
}

# Find the model with the maximum R2 score
# Use the dictionary's .get() method as the key for the max function
best_model = max(results, key=results.get)

# You can also print the best model and its R2 score
print(f"O melhor modelo é: {best_model}")
print(f"R2 do melhor modelo: {results[best_model]}")

"""# GridSearchCV

Agora iremos validar os modelos utilizando o GridSearchCV para validar se o modelo encontrado anteriormente de forma manual tem o resultado igual e também o método nos permite testar fácilmente vários hiperparâmetros.

Utilizando de forma automatizada garantimos que todos os modelos sejam testados de forma igual e justa, tendo mais confiança no resultado.

Outro ponto que o GridSearchCV nos tras é que ele mesmo já faz um cross-validation e evita o overfitting oferecendo uma estimativa muito mais segura.

Para isso, vamos recuperar novamente o mesmo dataset utilizado no início apenas para utilizar a pipeline dentro do próprio GridSearch.
"""

dfGrid = pd.read_csv('https://raw.githubusercontent.com/isoliveira20/POS-IA/refs/heads/main/health_insurance_dataset_v3.csv')

"""Iremos criar as variáveis de acordo com o tipo, apenas para ficar mais fácil ao utilizar no código sem ter que ficar sempre escrevendo os nomes das colunas"""

numerical_vars = [
    'age', 'income', 'num_dependents_kids', 'num_dependents_adult',
    'num_dependents_older', 'use_last_year', 'chronic_condition', 'occupation_risk'
]

bool_vars = [
    'smoker'
]

categorical_nominal_vars = [
    'sex', 'region', 'marital_status'
]

categorical_ordinal_vars = [
    'exercise_frequency', 'bmi',
    'diet_quality', 'education', 'alcohol_consumption', 'coverage_level',
    'genetic_risk'
]

target = 'charges'

"""O random state fixo em 42 para utilizarmos em todos os modelos."""

random_state = 42

"""Ordem das variáveis categóricas para usarmos depois no transformer com OrdinalEncoder"""

order_exercise_frequency = ['sedentary', 'light', 'moderate', 'active']
order_bmi = ['underweight', 'normal', 'overweight', 'obese']
order_diet_quality = ['poor', 'average', 'good']
order_education = ['primary', 'high_school', 'college', 'postgraduate']
order_alcohol_consumption = ['none', 'low', 'moderate', 'high']
order_coverage_level = ['basic', 'standard', 'premium']
order_genetic_risk = ['low', 'medium', 'high']

"""Agora iremos criar os transformers para cada tipo de dado"""

# Transformer para variáveis categóricas nominais (não tem uma ordem definida)
nominal_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Transformer para variáveis categóricas ordinais (tem uma ordem)
ordinal_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('ordinal', OrdinalEncoder(categories=[
        order_exercise_frequency,
        order_bmi,
        order_diet_quality,
        order_education,
        order_alcohol_consumption,
        order_coverage_level,
        order_genetic_risk
    ]))
])

# Transformer para variáveis numéricas
numerical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

# Transformer para variáveis booleanas
bool_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent'))
])

"""Criação do ColumnTransformer para aplicar as transformações criadas anteriormente, cada um sendo para um tipo específico"""

preprocessor = ColumnTransformer(
    transformers=[
        ('nominal', nominal_transformer, categorical_nominal_vars),
        ('ordinal', ordinal_transformer, categorical_ordinal_vars),
        ('bool', bool_transformer, bool_vars),
        ('num', numerical_transformer, numerical_vars)
    ]
)

"""Removendo o target (charges) do dataset X e armazenando seu valor no y"""

X = dfGrid.drop(columns=[target])
y = dfGrid[target]

"""Dividindo os dados em teste e treino, utilizando o `shuffle=True` para realizar embaralhamento dos dados e evitando viéses.

Dados de testes = 20%
Dados de treino = 80%
"""

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=random_state, shuffle=True)

"""Pipeline de processamento e modelagem"""

pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', LinearRegression())
])

"""Definição dos parâmetros a ser utilizado no GridSearchCV e seus respectivos modelos"""

param_grid = [
    {
        # Linear Regression
        'model': [LinearRegression()],
        'model__fit_intercept': [True],  # Ajustar o intercepto (termo constante)
        'model__positive': [False]       # Permitir coeficientes negativos
    },
    {
        # Lasso (Regressão com regularização L1)
        'model': [Lasso(max_iter=5000, random_state=random_state)],
        'model__alpha': [0.01, 0.1, 1],  # Valores para o parâmetro de regularização
        'model__selection': ['cyclic']   # Método de atualização dos coeficientes
    },
    {
        # Random Forest Regressor (ensemble de árvores)
        'model': [RandomForestRegressor(random_state=random_state)],
        'model__n_estimators': [100, 200],  # Número de árvores na floresta
        'model__max_depth': [None, 5, 10]   # Profundidade máxima das árvores (None = sem limite)
    },
    {
        #  XGBoost Regressor (boosting de árvores)
        'model': [XGBRegressor(objective='reg:squarederror', random_state=random_state)],
        'model__learning_rate': [0.1],         # Taxa de aprendizado
        'model__max_depth': [3, 5],            # Profundidade máxima das árvores
        'model__subsample': [1.0],             # Fração de amostras usadas para treinar cada árvore
        'model__colsample_bytree': [1.0],      # Fração de colunas usadas para cada árvore
        'model__n_estimators': [100],          # Número de árvores no modelo
        'model__gamma': [0],                   # Mínima redução de perda para fazer uma divisão
        'model__reg_lambda': [1]               # Parâmetro de regularização L2
    }
]

"""Criação e configuração do GridSearchCV utilizando a pipeline e os parâmetros mapeados para realizar a busca exaustiva dos melhores hiperparâmetros e modelos"""

grid_search = GridSearchCV(
    estimator=pipeline,      # Pipeline que inclui pré-processamento
    param_grid=param_grid,   # Grade de parâmetros para testar diferentes modelos e hiperparâmetros
    cv=5,                    # Validação cruzada com 5 folds para avaliação robusta
    scoring='r2',            # Métrica de avaliação: coeficiente de determinação R²
    n_jobs=1,                # Número de processos paralelos (1 = sem paralelismo)
    verbose=2,               # Nível de verbosidade para acompanhar o progresso da busca
    refit=True               # Após encontrar o melhor modelo, re-treina com todos os dados de treino
)

"""Executa a busca em grade para encontrar o melhor modelo e hiperparâmetros usando os dados de treino (X_train e y_train)"""

grid_search.fit(X_train, y_train)

"""Melhor parâmetro analisado"""

print("Melhores parâmetros:", grid_search.best_params_)

"""Recupera o melhor modelo analisado e realiza a predição no conjunto de teste usando o melhor modelo ajustado"""

best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

"""Calculando as métricas:

- MAE (Mean Absolute Error): média das diferenças absolutas entre valores reais e previstos; fácil de interpretar, mede o erro médio.

- MSE (Mean Squared Error): média dos quadrados das diferenças; penaliza erros maiores mais fortemente.

- RMSE (Root Mean Squared Error): raiz quadrada do MSE; traz a métrica para a mesma escala da variável alvo.

- R² (R squared): varia entre 0 e 1 (ou negativo se o modelo for pior que a média); quanto mais próximo de 1, melhor o ajuste.


"""

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

"""Mostrando os resultados calculados acima"""

print(f"MAE: {mae:.4f}")
print(f"RMSE: {rmse:.4f}")
print(f"R²: {r2:.4f}")

"""Transforma os resultados em DataFrame, identifica o melhor desempenho por modelo e exibe os melhores parâmetros e scores."""

results = pd.DataFrame(grid_search.cv_results_)

results['model_name'] = results['params'].apply(lambda x: type(x['model']).__name__)

summary = results.groupby('model_name')['mean_test_score'].max().sort_values(ascending=False)
print(summary)

best_params_per_model = results.loc[results.groupby('model_name')['mean_test_score'].idxmax(), ['model_name', 'params', 'mean_test_score']]
print(best_params_per_model)

"""# Gráfico de Valores Reais vs Valores Preditos
Gráfico comparando os valores reais e as previsões do modelo, mostrando a relação entre eles. A linha tracejada vermelha indica a linha de identidade (y = x), que representa predições perfeitas.
"""

plt.figure(figsize=(6,6))
sns.scatterplot(x=y_test, y=y_pred)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Valores Reais")
plt.ylabel("Valores Preditos")
plt.title("Predições vs Valores Reais")
plt.show()

"""# Análise do Gráfico

- **Alinhamento com a linha de perfeição**: A maioria dos pontos está bem próxima da linha vermelha, indicando que o modelo está fazendo previsões bastante precisas.

- **Distribuição dos pontos**: Os dados estão distribuídos de forma relativamente homogênea ao longo da linha, sem grandes desvios sistemáticos.

- **Ausência de padrões de erro**: Não há indícios claros de viés, como tendência dos pontos ficarem acima ou abaixo da linha em determinadas faixas de valores.

- **Leve dispersão nas extremidades**: Observa-se uma leve dispersão maior para valores mais altos, o que é comum em muitos modelos de regressão, mas ainda assim as predições permanecem próximas dos valores reais.


**Conclusão**

O modelo apresenta um desempenho muito bom, com alta capacidade de prever os valores do conjunto de teste.

# Gráfico de Resíduos
O gráfico exibe os resíduos (diferença entre valores reais e preditos) em função dos valores preditos pelo modelo. A linha horizontal vermelha em zero representa o ponto onde o modelo não comete erro.
"""

residuos = y_test - y_pred
plt.figure(figsize=(6,4))
sns.scatterplot(x=y_pred, y=residuos)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel("Valores Preditos")
plt.ylabel("Resíduos")
plt.title("Resíduos vs Valores Preditos")
plt.show()

"""# Análise do Gráfico

- **Padrão de funil (heterocedasticidade)**: Observa-se que, à medida que os valores preditos aumentam, a dispersão dos resíduos também aumenta. Isso caracteriza um padrão em forma de funil, indicando que o modelo apresenta heterocedasticidade. Ou seja, a variância dos erros não é constante — os erros são menores para valores preditos baixos e maiores para valores preditos altos.

- **Distribuição ao redor da linha zero**: Apesar da heterocedasticidade, os resíduos estão, em média, distribuídos em torno da linha zero, o que indica que não há viés sistemático (o modelo não está consistentemente superestimando ou subestimando).

- **Possível limitação do modelo**: O aumento da dispersão dos resíduos para valores preditos mais altos pode indicar que o modelo tem dificuldades em prever corretamente para essa faixa de valores.

# Gráfico de Importância das Features
Gráfico de barras mostrando a importância relativa de cada feature para o modelo
"""

preprocessor = grid_search.best_estimator_.named_steps['preprocessor']
model = grid_search.best_estimator_.named_steps['model']

# Extrair nomes das features já processadas
features = preprocessor.get_feature_names_out()

if hasattr(model, 'feature_importances_'):
    importances = model.feature_importances_

    plt.figure(figsize=(12, max(6, len(features)*0.3)))
    sns.barplot(x=importances, y=features)
    plt.title("Importância das Features")
    plt.xlabel("Importância")
    plt.ylabel("Features")
    plt.tight_layout()
    plt.show()
else:
    print("O modelo selecionado não possui atributo 'feature_importances_'.")

"""# Análise do Gráfico

Feature mais importante:
- **num__age** se destaca como a de maior importância, contribuindo significativamente mais do que todas as outras para as decisões do modelo.

Outras features relevantes:

- num__num_dependents_kids (número de dependentes crianças)
- num__num_dependents_older (número de dependentes idosos)
- num__income (renda)
- ordinal__coverage_level (nível de cobertura)
- num__num_dependents_adult (número de dependentes adultos)
- bool__smoker (fumante)

# Cross-validation (Melhor modelo do GridSearchCV)

Agora iremos utilizar a validação cruzada para avaliar o desempenho do modelo de forma mais robusta e confiável. Essa técnica divide os dados em várias partes, treinando e testando o modelo em diferentes combinações, o que garante que a avaliação não dependa de uma única divisão dos dados.

Com a validação cruzada, evitamos que o modelo se ajuste demais aos dados de treino (overfitting) e obtemos uma estimativa mais precisa da sua capacidade de generalizar para dados novos.

Dessa forma, a validação cruzada oferece uma avaliação justa e consistente, aumentando nossa confiança nos resultados do modelo.
"""

scoring = {
    'MAE': 'neg_mean_absolute_error',
    'RMSE': 'neg_root_mean_squared_error',
    'R2': 'r2'
}

cv_results = cross_validate(
    best_model,                # modelo treinado a ser avaliado
    X, y,                      # dados de entrada (features) e saída (target)
    cv=5,                      # número de folds para validação cruzada (5 folds)
    scoring=scoring,           # métricas para avaliar o desempenho do modelo
    n_jobs=-1,                 # usa todos os processadores disponíveis para paralelizar
    return_train_score=False   # não retorna as métricas do conjunto de treino
)

"""Converte os valores retornados do cross_validate para números positivos pois é retornado no MAE e RMSE valores negativos para que possam ser maximizadas internamente, o R² sempre retorna positivo então não é necessário a conversão."""

mae_scores = -cv_results['test_MAE']
rmse_scores = -cv_results['test_RMSE']
r2_scores = cv_results['test_R2']

print(f"CV MAE médio: {mae_scores.mean():.4f} ± {mae_scores.std():.4f}")
print(f"CV RMSE médio: {rmse_scores.mean():.4f} ± {rmse_scores.std():.4f}")
print(f"CV R² médio: {r2_scores.mean():.4f} ± {r2_scores.std():.4f}")

"""# Análise dos Resultados

- O modelo apresenta excelente desempenho com um R² muito alto, indicando que ele captura muito bem a relação entre as variáveis.

- Os erros MAE e RMSE são relativamente baixos e consistentes, indicando previsões precisas e estáveis.

- A diferença entre MAE e RMSE sugere que existem alguns erros maiores, mas eles não comprometem a qualidade geral do modelo.

- A baixa variação dos resultados entre os folds reforça a robustez e generalização do modelo.

# Gráfico da Distribuição das Métricas

Boxplot para mostrar a variação das métricas MAE, RMSE e R² obtidas em cada fold. Permite avaliar a consistência e a robustez do modelo, mostrando a dispersão dos resultados e possíveis outliers em cada métrica.
"""

df_scores = pd.DataFrame({
    'MAE': -cv_results['test_MAE'],
    'RMSE': -cv_results['test_RMSE'],
    'R2': cv_results['test_R2']
})

plt.figure(figsize=(10,6))
sns.boxplot(data=df_scores)
plt.title('Distribuição das métricas por fold na validação cruzada')
plt.ylabel('Valor da métrica')
plt.show()

"""# Análise do Gráfico

- O modelo mostra boa consistência nas métricas MAE e RMSE, com baixa variabilidade entre os folds.

- O outlier em R² indica que pode haver uma certa sensibilidade aos dados, especialmente em relação à capacidade explicativa.

### Conclusão
No geral, a dispersão das métricas é pequena, o que sugere que o modelo é robusto e estável na maioria dos folds, mas deve-se investigar o fold com desempenho discrepante para entender possíveis causas.

# Gráfico de Evolução das Métricas por Fold
Gráfico para mostrar a variação dos valores das métricas MAE, RMSE e R² em cada um dos folds da validação cruzada, permitindo visualizar a consistência e o desempenho do modelo em cada divisão dos dados.
"""

plt.figure(figsize=(10,6))
for metric in df_scores.columns:
    plt.figure(figsize=(8, 4))
    plt.plot(range(1, len(df_scores)+1), df_scores[metric], marker='o')
    plt.xlabel('Fold')
    plt.ylabel(f'Valor da métrica ({metric})')
    plt.title(f'{metric} por fold na validação cruzada')
    plt.grid(True)
    plt.show()

"""# Análise dos Gráficos
### MAE por Fold
- Fold 1: ~671,7
- Fold 2: ~684,4 (maior valor)
- Fold 3: ~674,1 (menor valor)
- Fold 4: ~681,9
- Fold 5: ~683,6

Conclusão: Baixa variação entre os folds, com valores muito próximos (entre ~672 e ~684), o que indica boa estabilidade do modelo em relação ao erro médio das previsões

### RMSE por Fold
- Fold 1: ~1164
- Fold 2: ~1183 (maior valor)
- Fold 3: ~1139 (menor valor)
- Fold 4: ~1170
- Fold 5: ~1177

Conclusão: Apesar de uma variação um pouco maior em comparação ao MAE (de ~1139 a ~1183), os valores seguem relativamente estáveis, sugerindo que não há grandes desvios nas previsões. O RMSE maior que o MAE é esperado, pois penaliza mais fortemente os erros maiores.

### R² por Fold
- Fold 1: ~0.99603
- Fold 2: ~0.99588 (menor valor)
- Fold 3: ~0.99621 (maior valor)
- Fold 4: ~0.99598
- Fold 5: ~0.99596

Conclusão: Valores consistentemente alto (acima de 0.995 em todos os folds), o que indica que o modelo é capaz de explicar mais de 99,5% da variância da variável alvo.

## Conclusão
O modelo apresenta alta consistência e robustez entre os folds da validação cruzada. As três métricas juntas mostram que:

- Erros são baixos e estáveis.

- O modelo generaliza bem para diferentes subconjuntos dos dados.

- Possui forte capacidade explicativa.

Isso indica que o modelo está bem ajustado e não sofre de grandes variações nem overfitting/underfitting visíveis.
"""